{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Bring your own script with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow script mode training and serving\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script. In this example, we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In this example, we will show how easily you can train a SageMaker using TensorFlow 1.x and TensorFlow 2.0 scripts with SageMaker Python SDK. In addition, this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. For full documentation on the TensorFlow Serving container, please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "The MNIST dataset has been loaded to the public S3 buckets `sagemaker-sample-data-<REGION>` under the prefix `tensorflow/mnist`. There are four .npy file under this prefix:\n",
    "\n",
    "- train_data.npy\n",
    "- eval_data.npy\n",
    "- train_labels.npy\n",
    "- eval_labels.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "training_data_uri = 's3://sagemaker-sample-data-{}/tensorflow/mnist'.format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the `model_dir` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable `SM_MODEL_DIR`, which always points to `/opt/ml/model`. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2018-2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\n",
      "\u001b[33m\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m division\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpython\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mplatform\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tf_logging\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_logging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_sys\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcnn_model_fn\u001b[39;49;00m(features, labels, mode):\n",
      "    \u001b[33m\"\"\"Model function for CNN.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[37m# Input Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Reshape X to 4-D tensor: [batch_size, width, height, channels]\u001b[39;49;00m\n",
      "    \u001b[37m# MNIST images are 28x28 pixels, and have one color channel\u001b[39;49;00m\n",
      "    input_layer = tf.reshape(features[\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], [-\u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 32 features using a 5x5 filter with ReLU activation.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 1]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    conv1 = tf.layers.conv2d(\n",
      "        inputs=input_layer,\n",
      "        filters=\u001b[34m32\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# First max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 64 features using a 5x5 filter.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    conv2 = tf.layers.conv2d(\n",
      "        inputs=pool1,\n",
      "        filters=\u001b[34m64\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Second max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Flatten tensor into a batch of vectors\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    pool2_flat = tf.reshape(pool2, [-\u001b[34m1\u001b[39;49;00m, \u001b[34m7\u001b[39;49;00m * \u001b[34m7\u001b[39;49;00m * \u001b[34m64\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Dense Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Densely connected layer with 1024 neurons\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Add dropout operation; 0.6 probability that element will be kept\u001b[39;49;00m\n",
      "    dropout = tf.layers.dropout(\n",
      "        inputs=dense, rate=\u001b[34m0.4\u001b[39;49;00m, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
      "\n",
      "    \u001b[37m# Logits layer\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 10]\u001b[39;49;00m\n",
      "    logits = tf.layers.dense(inputs=dropout, units=\u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    predictions = {\n",
      "        \u001b[37m# Generate predictions (for PREDICT and EVAL mode)\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.argmax(\u001b[36minput\u001b[39;49;00m=logits, axis=\u001b[34m1\u001b[39;49;00m),\n",
      "        \u001b[37m# Add `softmax_tensor` to the graph. It is used for PREDICT and by the\u001b[39;49;00m\n",
      "        \u001b[37m# `logging_hook`.\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.nn.softmax(logits, name=\u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    }\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.PREDICT:\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
      "\n",
      "    \u001b[37m# Calculate Loss (for both TRAIN and EVAL modes)\u001b[39;49;00m\n",
      "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
      "\n",
      "    \u001b[37m# Configure the Training Op (for TRAIN mode)\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.TRAIN:\n",
      "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=\u001b[34m0.001\u001b[39;49;00m)\n",
      "      train_op = optimizer.minimize(\n",
      "          loss=loss,\n",
      "          global_step=tf.train.get_global_step())\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
      "\n",
      "    \u001b[37m# Add evaluation metrics (for EVAL mode)\u001b[39;49;00m\n",
      "    eval_metric_ops = {\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.metrics.accuracy(\n",
      "            labels=labels, predictions=predictions[\u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(\n",
      "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mserving_input_fn\u001b[39;49;00m():\n",
      "    inputs = {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.placeholder(tf.float32, [\u001b[34mNone\u001b[39;49;00m, \u001b[34m784\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    \u001b[37m# Create the Estimator\u001b[39;49;00m\n",
      "    mnist_classifier = tf.estimator.Estimator(\n",
      "        model_fn=cnn_model_fn, model_dir=args.model_dir)\n",
      "\n",
      "    \u001b[37m# Set up logging for predictions\u001b[39;49;00m\n",
      "    \u001b[37m# Log the values in the \"Softmax\" tensor with label \"probabilities\"\u001b[39;49;00m\n",
      "    tensors_to_log = {\u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}\n",
      "    logging_hook = tf.train.LoggingTensorHook(\n",
      "        tensors=tensors_to_log, every_n_iter=\u001b[34m50\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\n",
      "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: train_data},\n",
      "        y=train_labels,\n",
      "        batch_size=\u001b[34m100\u001b[39;49;00m,\n",
      "        num_epochs=\u001b[34mNone\u001b[39;49;00m,\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Evaluate the model and print results\u001b[39;49;00m\n",
      "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: eval_data},\n",
      "        y=eval_labels,\n",
      "        num_epochs=\u001b[34m1\u001b[39;49;00m,\n",
      "        shuffle=\u001b[34mFalse\u001b[39;49;00m)\n",
      "\n",
      "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=\u001b[34m20000\u001b[39;49;00m)\n",
      "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n",
      "    tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        mnist_classifier.export_savedmodel(args.sm_model_dir, serving_input_fn)\n",
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\n",
      "    \u001b[33m\"\"\"Generate a simple model\"\"\"\u001b[39;49;00m\n",
      "    model = tf.keras.models.Sequential([\n",
      "        tf.keras.layers.Flatten(),\n",
      "        tf.keras.layers.Dense(\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu),\n",
      "        tf.keras.layers.Dropout(\u001b[34m0.4\u001b[39;49;00m),\n",
      "        tf.keras.layers.Dense(\u001b[34m10\u001b[39;49;00m, activation=tf.nn.softmax)\n",
      "    ])\n",
      "\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    model.fit(x_train, y_train)\n",
      "    model.evaluate(x_test, y_test)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST training data\"\"\"\u001b[39;49;00m\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST testing data\"\"\"\u001b[39;49;00m\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        \u001b[37m# save model to an S3 directory with version number '00000001' in Tensorflow SavedModel Format\u001b[39;49;00m\n",
      "        \u001b[37m# To export the model as h5 format use model.save('my_model.h5')\u001b[39;49;00m\n",
      "        mnist_classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n"
     ]
    }
   ],
   "source": [
    "# cell 03\n",
    "\n",
    "!pygmentize 'mnist.py'\n",
    "\n",
    "# TensorFlow 2.1 script\n",
    "!pygmentize 'mnist-2.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training job using the TensorFlow estimator\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "`py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting py_version to `py2` and `script_mode` to True.\n",
    "\n",
    "`distribution` is used to configure the distributed training setup. It's required only if you are doing distributed training either across a cluster of instances or across multiple GPUs. Here we are using parameter servers as the distributed training schema. SageMaker training jobs run on homogeneous clusters. To make parameter server more performant in the SageMaker setup, we run a parameter server on every instance in the cluster, so there is no need to specify the number of parameter servers to launch. Script mode also supports distributed training with [Horovod](https://github.com/horovod/horovod). You can find the full documentation on how to configure distributions [here](https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#distributed-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 04\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             instance_count=2,\n",
    "                             instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='1.15.2',\n",
    "                             py_version='py3',\n",
    "                             distribution={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initiate an estimator to train with TensorFlow 2.1 script. The only things that you will need to change are the script name and `framework_version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "mnist_estimator2 = TensorFlow(entry_point='mnist-2.py',\n",
    "                             role=role,\n",
    "                             instance_count=2,\n",
    "                             instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='2.1.0',\n",
    "                             py_version='py3',\n",
    "                             distribution={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling `fit`\n",
    "To start a training job, we call `estimator.fit(training_data_uri)`.\n",
    "\n",
    "An S3 location is used here as the input. fit creates a default channel named 'training', which points to this S3 location. In the training script we can then access the training data from the location stored in SM_CHANNEL_TRAINING. fit accepts a couple other types of input as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "\n",
    "When training starts, the TensorFlow container executes mnist.py, passing hyperparameters and model_dir from the estimator as script arguments. Because we didn't define either in this example, no hyperparameters are passed, and model_dir defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`, so the script execution is as follows:\n",
    "\n",
    "`python mnist.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`\n",
    "\n",
    "When training is complete, the training job will upload the saved model for TensorFlow serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13 06:50:46 Starting - Starting the training job...\n",
      "2021-08-13 06:51:09 Starting - Launching requested ML instancesProfilerReport-1628837445: InProgress\n",
      "......\n",
      "2021-08-13 06:52:09 Starting - Preparing the instances for training.........\n",
      "2021-08-13 06:53:38 Downloading - Downloading input data...\n",
      "2021-08-13 06:54:10 Training - Downloading the training image...\n",
      "2021-08-13 06:54:39 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:42,902 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:43,280 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:43,280 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:43,281 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:43,281 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:43,281 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:44,105 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2021-08-13 06:54:44,420 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-08-13-06-50-45-572\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-08-13-06-50-45-572\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:44,842 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:45,255 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:45,256 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:45,256 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:45,256 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:45,257 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:46,111 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-13 06:54:46,376 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tensorflow-training-2021-08-13-06-50-45-572\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tensorflow-training-2021-08-13-06-50-45-572\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-us-east-1-783605285449/tensorflow-training-2021-08-13-06-50-45-572/model/model.ckpt.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2884865, step = 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2884865, step = 0\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.3028107, step = 37\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.3028107, step = 37\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2753642, step = 128 (6.086 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2753642, step = 128 (6.086 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 48.9024\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 48.9024\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2494297, step = 234 (3.128 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2494297, step = 234 (3.128 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 49.8851\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 49.8851\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2204635, step = 380 (2.857 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2204635, step = 380 (2.857 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.5767\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.5767\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.193197, step = 442 (6.153 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.193197, step = 442 (6.153 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.5827\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.5827\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1799777, step = 526 (2.814 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1799777, step = 526 (2.814 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.9869\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.9869\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1080532, step = 671 (2.824 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1080532, step = 671 (2.824 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.9852\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.9852\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0111454, step = 761 (6.233 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0111454, step = 761 (6.233 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.3056\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.3056\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.0518372, step = 817 (2.857 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.0518372, step = 817 (2.857 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.0911\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.0911\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.8130231, step = 963 (2.835 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.8130231, step = 963 (2.835 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.9215\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.9215\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.7400653, step = 1079 (6.155 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.7400653, step = 1079 (6.155 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.2272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.2272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.6400545, step = 1108 (2.784 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.6400545, step = 1108 (2.784 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.8089\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.8089\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.378662, step = 1254 (2.846 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.378662, step = 1254 (2.846 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.7037\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.7037\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.7252\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.7252\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.1790112, step = 1399 (2.812 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.1790112, step = 1399 (2.812 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.1457835, step = 1401 (6.243 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.1457835, step = 1401 (6.243 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1845\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1845\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.97793996, step = 1544 (2.740 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.97793996, step = 1544 (2.740 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8368\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8368\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7857409, step = 1687 (2.707 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7857409, step = 1687 (2.707 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.5654\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.5654\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.8413646, step = 1725 (6.097 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.8413646, step = 1725 (6.097 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3883\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3883\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.74508035, step = 1832 (2.716 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.74508035, step = 1832 (2.716 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.0089\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.0089\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8620587, step = 1977 (2.824 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8620587, step = 1977 (2.824 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.5919\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.5919\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5862008, step = 2048 (6.160 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5862008, step = 2048 (6.160 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.9805\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.9805\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6136774, step = 2122 (2.752 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6136774, step = 2122 (2.752 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.5617\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.5617\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5880575, step = 2265 (2.658 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5880575, step = 2265 (2.658 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9298\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9298\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5262807, step = 2372 (6.098 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5262807, step = 2372 (6.098 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1183\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1183\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5631009, step = 2411 (2.755 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5631009, step = 2411 (2.755 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.5866\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.5866\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.47700334, step = 2555 (2.719 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.47700334, step = 2555 (2.719 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3263\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3263\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.674023, step = 2700 (2.712 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.674023, step = 2700 (2.712 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.7054\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.7054\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.31319895, step = 2696 (6.110 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.31319895, step = 2696 (6.110 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.1616\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.1616\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5111444, step = 2844 (2.678 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5111444, step = 2844 (2.678 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2175\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2175\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35717607, step = 2987 (2.657 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35717607, step = 2987 (2.657 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3909\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.3909\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3289596, step = 3024 (6.074 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3289596, step = 3024 (6.074 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7463\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7463\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.614222, step = 3131 (2.653 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.614222, step = 3131 (2.653 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8727\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8727\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.41406927, step = 3276 (2.727 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.41406927, step = 3276 (2.727 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.4072\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.4072\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.39758575, step = 3351 (6.097 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.39758575, step = 3351 (6.097 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9476\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9476\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48419213, step = 3419 (2.678 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.48419213, step = 3419 (2.678 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.4831\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 51.4831\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.55768114, step = 3564 (2.790 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.55768114, step = 3564 (2.790 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1018\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.47523266, step = 3676 (6.122 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.47523266, step = 3676 (6.122 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5543\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5543\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.36634585, step = 3707 (2.625 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.36634585, step = 3707 (2.625 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0166\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0166\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42007703, step = 3851 (2.665 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42007703, step = 3851 (2.665 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2429\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2429\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.51538354, step = 3994 (2.598 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.51538354, step = 3994 (2.598 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 55.3339\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 55.3339\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2532485, step = 4006 (6.058 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2532485, step = 4006 (6.058 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8652\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8652\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35972148, step = 4138 (2.660 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35972148, step = 4138 (2.660 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0749\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0749\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29301274, step = 4281 (2.641 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29301274, step = 4281 (2.641 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5392\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5392\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.38698676, step = 4335 (6.079 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.38698676, step = 4335 (6.079 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4986\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4986\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.38806698, step = 4425 (2.638 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.38806698, step = 4425 (2.638 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.6729\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.6729\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20442617, step = 4567 (2.637 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20442617, step = 4567 (2.637 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.424\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.424\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32438838, step = 4663 (6.073 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32438838, step = 4663 (6.073 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35572442, step = 4711 (2.674 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35572442, step = 4711 (2.674 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.7336\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.7336\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4904\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4904\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3154906, step = 4854 (2.617 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3154906, step = 4854 (2.617 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.3896\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.3896\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.31065646, step = 4998 (2.657 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.31065646, step = 4998 (2.657 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8024\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.8024\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.34272385, step = 4993 (6.073 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.34272385, step = 4993 (6.073 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4857\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4857\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2763849, step = 5142 (2.651 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2763849, step = 5142 (2.651 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.1487\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.1487\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35922074, step = 5286 (2.666 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35922074, step = 5286 (2.666 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2374\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2374\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.33562225, step = 5322 (6.065 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.33562225, step = 5322 (6.065 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0176\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0176\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27008197, step = 5429 (2.653 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27008197, step = 5429 (2.653 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9268\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9268\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3244587, step = 5574 (2.711 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3244587, step = 5574 (2.711 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.4138\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.4138\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2889745, step = 5719 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2889745, step = 5719 (2.694 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.2018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.2018\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2549887, step = 5648 (6.056 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2549887, step = 5648 (6.056 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1451\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1451\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.30638927, step = 5863 (2.699 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.30638927, step = 5863 (2.699 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2551\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2551\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3775708, step = 5973 (6.077 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3775708, step = 5973 (6.077 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.25819844, step = 6007 (2.669 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.25819844, step = 6007 (2.669 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.245\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.245\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2378\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.2378\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22350433, step = 6150 (2.632 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22350433, step = 6150 (2.632 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.2013\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.2013\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29327214, step = 6298 (2.871 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29327214, step = 6298 (2.871 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.3256\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.3256\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.37399918, step = 6294 (6.056 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.37399918, step = 6294 (6.056 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.6661\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.6661\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.33926675, step = 6441 (2.629 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.33926675, step = 6441 (2.629 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.1135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22227617, step = 6585 (2.735 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22227617, step = 6585 (2.735 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.6192\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.6192\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18225907, step = 6622 (6.129 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18225907, step = 6622 (6.129 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.7214\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.7214\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42486727, step = 6730 (2.731 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42486727, step = 6730 (2.731 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1525\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 52.1525\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24915704, step = 6875 (2.750 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24915704, step = 6875 (2.750 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7842\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7842\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.24316575, step = 6946 (6.087 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.24316575, step = 6946 (6.087 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.272275, step = 7018 (2.606 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.272275, step = 7018 (2.606 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.9777\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.9777\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0573\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0573\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18569313, step = 7162 (2.632 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18569313, step = 7162 (2.632 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7235\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.7235\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.41909477, step = 7277 (6.058 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.41909477, step = 7277 (6.058 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24060012, step = 7305 (2.624 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24060012, step = 7305 (2.624 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4868\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4868\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.4431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.4431\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.31269905, step = 7450 (2.707 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.31269905, step = 7450 (2.707 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4194\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.4194\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2913988, step = 7593 (2.637 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2913988, step = 7593 (2.637 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2213158, step = 7605 (6.076 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2213158, step = 7605 (6.076 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0763\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.0763\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5756\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5756\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17486495, step = 7736 (2.635 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17486495, step = 7736 (2.635 sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# cell 06\n",
    "mnist_estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit to train a model with TensorFlow 2.1 script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-11 12:05:50 Starting - Starting the training job...\n",
      "2021-08-11 12:06:14 Starting - Launching requested ML instancesProfilerReport-1628683549: InProgress\n",
      "......\n",
      "2021-08-11 12:07:14 Starting - Preparing the instances for training.........\n",
      "2021-08-11 12:08:44 Downloading - Downloading input data\n",
      "2021-08-11 12:08:44 Training - Downloading the training image.........\n",
      "2021-08-11 12:10:15 Training - Training image download completed. Training in progress.\u001b[34m2021-08-11 12:10:12,018 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:12,298 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:12,298 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:12,298 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:13,149 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:13,356 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-08-11-12-05-49-257\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist-2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist-2.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist-2.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist-2\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-08-11-12-05-49-257\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\",\"module_name\":\"mnist-2\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist-2.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 mnist-2.py --model_dir s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:09,902 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:10,251 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:10,251 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:10,251 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:11,057 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:11,319 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tensorflow-training-2021-08-11-12-05-49-257\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist-2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist-2.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist-2.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist-2\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tensorflow-training-2021-08-11-12-05-49-257\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/source/sourcedir.tar.gz\",\"module_name\":\"mnist-2\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist-2.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/bin/python3 mnist-2.py --model_dir s3://sagemaker-us-east-1-365792799466/tensorflow-training-2021-08-11-12-05-49-257/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mTrain on 55000 samples\u001b[0m\n",
      "\u001b[34mTrain on 55000 samples\u001b[0m\n",
      "\u001b[35m#015   32/55000 [..............................] - ETA: 29:59 - loss: 2.4527 - accuracy: 0.0312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  736/55000 [..............................] - ETA: 1:21 - loss: 1.2259 - accuracy: 0.6318 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1472/55000 [..............................] - ETA: 41s - loss: 0.9356 - accuracy: 0.7201 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2208/55000 [>.............................] - ETA: 28s - loss: 0.7728 - accuracy: 0.7659#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2912/55000 [>.............................] - ETA: 22s - loss: 0.7081 - accuracy: 0.7902#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3616/55000 [>.............................] - ETA: 18s - loss: 0.6577 - accuracy: 0.8059#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4320/55000 [=>............................] - ETA: 15s - loss: 0.6174 - accuracy: 0.8167#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5056/55000 [=>............................] - ETA: 13s - loss: 0.5854 - accuracy: 0.8261#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5792/55000 [==>...........................] - ETA: 12s - loss: 0.5554 - accuracy: 0.8348#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6528/55000 [==>...........................] - ETA: 11s - loss: 0.5282 - accuracy: 0.8422#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7264/55000 [==>...........................] - ETA: 10s - loss: 0.5031 - accuracy: 0.8499#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8000/55000 [===>..........................] - ETA: 9s - loss: 0.4811 - accuracy: 0.8571 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8736/55000 [===>..........................] - ETA: 8s - loss: 0.4668 - accuracy: 0.8610#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9472/55000 [====>.........................] - ETA: 8s - loss: 0.4535 - accuracy: 0.8648#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510208/55000 [====>.........................] - ETA: 7s - loss: 0.4415 - accuracy: 0.8672#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510944/55000 [====>.........................] - ETA: 7s - loss: 0.4309 - accuracy: 0.8702#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511616/55000 [=====>........................] - ETA: 6s - loss: 0.4243 - accuracy: 0.8723#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512288/55000 [=====>........................] - ETA: 6s - loss: 0.4134 - accuracy: 0.8757#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512896/55000 [======>.......................] - ETA: 6s - loss: 0.4066 - accuracy: 0.8781#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01513632/55000 [======>.......................] - ETA: 6s - loss: 0.3973 - accuracy: 0.8806#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514368/55000 [======>.......................] - ETA: 5s - loss: 0.3888 - accuracy: 0.8833#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515072/55000 [=======>......................] - ETA: 5s - loss: 0.3816 - accuracy: 0.8856#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515776/55000 [=======>......................] - ETA: 5s - loss: 0.3751 - accuracy: 0.8875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516512/55000 [========>.....................] - ETA: 5s - loss: 0.3679 - accuracy: 0.8896#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517184/55000 [========>.....................] - ETA: 5s - loss: 0.3620 - accuracy: 0.8909#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517920/55000 [========>.....................] - ETA: 4s - loss: 0.3559 - accuracy: 0.8927#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518624/55000 [=========>....................] - ETA: 4s - loss: 0.3523 - accuracy: 0.8941#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519328/55000 [=========>....................] - ETA: 4s - loss: 0.3476 - accuracy: 0.8954#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520032/55000 [=========>....................] - ETA: 4s - loss: 0.3431 - accuracy: 0.8968#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520768/55000 [==========>...................] - ETA: 4s - loss: 0.3402 - accuracy: 0.8977#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521472/55000 [==========>...................] - ETA: 4s - loss: 0.3368 - accuracy: 0.8991#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522176/55000 [===========>..................] - ETA: 3s - loss: 0.3336 - accuracy: 0.8999#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522880/55000 [===========>..................] - ETA: 3s - loss: 0.3306 - accuracy: 0.9009#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523584/55000 [===========>..................] - ETA: 3s - loss: 0.3262 - accuracy: 0.9021#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524320/55000 [============>.................] - ETA: 3s - loss: 0.3224 - accuracy: 0.9032#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525056/55000 [============>.................] - ETA: 3s - loss: 0.3186 - accuracy: 0.9045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525760/55000 [=============>................] - ETA: 3s - loss: 0.3155 - accuracy: 0.9055#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01526496/55000 [=============>................] - ETA: 3s - loss: 0.3124 - accuracy: 0.9062#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527200/55000 [=============>................] - ETA: 3s - loss: 0.3085 - accuracy: 0.9074#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527904/55000 [==============>...............] - ETA: 2s - loss: 0.3050 - accuracy: 0.9082#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528640/55000 [==============>...............] - ETA: 2s - loss: 0.3019 - accuracy: 0.9090#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529376/55000 [===============>..............] - ETA: 2s - loss: 0.2989 - accuracy: 0.9101#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530112/55000 [===============>..............] - ETA: 2s - loss: 0.2960 - accuracy: 0.9108#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530848/55000 [===============>..............] - ETA: 2s - loss: 0.2933 - accuracy: 0.9117#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01531520/55000 [================>.............] - ETA: 2s - loss: 0.2918 - accuracy: 0.9122#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532224/55000 [================>.............] - ETA: 2s - loss: 0.2891 - accuracy: 0.9128#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532960/55000 [================>.............] - ETA: 2s - loss: 0.2858 - accuracy: 0.9138#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533696/55000 [=================>............] - ETA: 2s - loss: 0.2837 - accuracy: 0.9143#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01534400/55000 [=================>............] - ETA: 2s - loss: 0.2820 - accuracy: 0.9148#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535136/55000 [==================>...........] - ETA: 2s - loss: 0.2794 - accuracy: 0.9157#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535840/55000 [==================>...........] - ETA: 1s - loss: 0.2770 - accuracy: 0.9164#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536576/55000 [==================>...........] - ETA: 1s - loss: 0.2744 - accuracy: 0.9172#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01537312/55000 [===================>..........] - ETA: 1s - loss: 0.2720 - accuracy: 0.9178#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538048/55000 [===================>..........] - ETA: 1s - loss: 0.2691 - accuracy: 0.9187#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538752/55000 [====================>.........] - ETA: 1s - loss: 0.2675 - accuracy: 0.9192#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539456/55000 [====================>.........] - ETA: 1s - loss: 0.2658 - accuracy: 0.9195#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540192/55000 [====================>.........] - ETA: 1s - loss: 0.2643 - accuracy: 0.9202#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540928/55000 [=====================>........] - ETA: 1s - loss: 0.2627 - accuracy: 0.9209#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541664/55000 [=====================>........] - ETA: 1s - loss: 0.2605 - accuracy: 0.9215#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01542400/55000 [======================>.......] - ETA: 1s - loss: 0.2586 - accuracy: 0.9220#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543136/55000 [======================>.......] - ETA: 1s - loss: 0.2567 - accuracy: 0.9226#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543872/55000 [======================>.......] - ETA: 1s - loss: 0.2550 - accuracy: 0.9231#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544576/55000 [=======================>......] - ETA: 0s - loss: 0.2536 - accuracy: 0.9236#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545312/55000 [=======================>......] - ETA: 0s - loss: 0.2517 - accuracy: 0.9241#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545984/55000 [========================>.....] - ETA: 0s - loss: 0.2501 - accuracy: 0.9245#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01546688/55000 [========================>.....] - ETA: 0s - loss: 0.2488 - accuracy: 0.9250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01547392/55000 [========================>.....] - ETA: 0s - loss: 0.2472 - accuracy: 0.9254#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548128/55000 [=========================>....] - ETA: 0s - loss: 0.2462 - accuracy: 0.9258#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548832/55000 [=========================>....] - ETA: 0s - loss: 0.2448 - accuracy: 0.9263#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549536/55000 [==========================>...] - ETA: 0s - loss: 0.2436 - accuracy: 0.9266#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550240/55000 [==========================>...] - ETA: 0s - loss: 0.2423 - accuracy: 0.9269#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550944/55000 [==========================>...] - ETA: 0s - loss: 0.2408 - accuracy: 0.9274#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551680/55000 [===========================>..] - ETA: 0s - loss: 0.2398 - accuracy: 0.9278#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01552416/55000 [===========================>..] - ETA: 0s - loss: 0.2385 - accuracy: 0.9282#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553152/55000 [===========================>..] - ETA: 0s - loss: 0.2366 - accuracy: 0.9287#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553856/55000 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9291#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554592/55000 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9294#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01555000/55000 [==============================] - 5s 91us/sample - loss: 0.2341 - accuracy: 0.9294\u001b[0m\n",
      "\u001b[35m#015   32/10000 [..............................] - ETA: 23s - loss: 0.0583 - accuracy: 0.9688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  960/10000 [=>............................] - ETA: 1s - loss: 0.1095 - accuracy: 0.9698 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1920/10000 [====>.........................] - ETA: 0s - loss: 0.1474 - accuracy: 0.9563#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2848/10000 [=======>......................] - ETA: 0s - loss: 0.1491 - accuracy: 0.9547#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3776/10000 [==========>...................] - ETA: 0s - loss: 0.1474 - accuracy: 0.9558#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4608/10000 [============>.................] - ETA: 0s - loss: 0.1551 - accuracy: 0.9531#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5568/10000 [===============>..............] - ETA: 0s - loss: 0.1438 - accuracy: 0.9564#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6528/10000 [==================>...........] - ETA: 0s - loss: 0.1372 - accuracy: 0.9580#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7456/10000 [=====================>........] - ETA: 0s - loss: 0.1280 - accuracy: 0.9611#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8416/10000 [========================>.....] - ETA: 0s - loss: 0.1196 - accuracy: 0.9638#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9376/10000 [===========================>..] - ETA: 0s - loss: 0.1116 - accuracy: 0.9664#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510000/10000 [==============================] - 1s 62us/sample - loss: 0.1139 - accuracy: 0.9654\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:22,428 sagemaker_tensorflow_container.training INFO     master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:22,428 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[35m2021-08-11 12:10:22,428 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015   32/55000 [..............................] - ETA: 30:17 - loss: 2.4914 - accuracy: 0.0625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  768/55000 [..............................] - ETA: 1:18 - loss: 1.2803 - accuracy: 0.6302 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1536/55000 [..............................] - ETA: 40s - loss: 0.9159 - accuracy: 0.7285 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2304/55000 [>.............................] - ETA: 27s - loss: 0.7764 - accuracy: 0.7656#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3072/55000 [>.............................] - ETA: 21s - loss: 0.6996 - accuracy: 0.7887#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3840/55000 [=>............................] - ETA: 17s - loss: 0.6467 - accuracy: 0.8023#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4608/55000 [=>............................] - ETA: 14s - loss: 0.5995 - accuracy: 0.8164#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5344/55000 [=>............................] - ETA: 13s - loss: 0.5702 - accuracy: 0.8243#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6112/55000 [==>...........................] - ETA: 11s - loss: 0.5408 - accuracy: 0.8351#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6880/55000 [==>...........................] - ETA: 10s - loss: 0.5177 - accuracy: 0.8404#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7648/55000 [===>..........................] - ETA: 9s - loss: 0.4962 - accuracy: 0.8470 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8416/55000 [===>..........................] - ETA: 8s - loss: 0.4842 - accuracy: 0.8518#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9120/55000 [===>..........................] - ETA: 8s - loss: 0.4722 - accuracy: 0.8549#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9888/55000 [====>.........................] - ETA: 7s - loss: 0.4557 - accuracy: 0.8603#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510656/55000 [====>.........................] - ETA: 7s - loss: 0.4389 - accuracy: 0.8666#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511424/55000 [=====>........................] - ETA: 6s - loss: 0.4275 - accuracy: 0.8698#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512192/55000 [=====>........................] - ETA: 6s - loss: 0.4179 - accuracy: 0.8729#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512960/55000 [======>.......................] - ETA: 6s - loss: 0.4090 - accuracy: 0.8759#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01513728/55000 [======>.......................] - ETA: 5s - loss: 0.4025 - accuracy: 0.8777#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514496/55000 [======>.......................] - ETA: 5s - loss: 0.3955 - accuracy: 0.8798#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515264/55000 [=======>......................] - ETA: 5s - loss: 0.3881 - accuracy: 0.8819#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516032/55000 [=======>......................] - ETA: 5s - loss: 0.3822 - accuracy: 0.8837#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516800/55000 [========>.....................] - ETA: 4s - loss: 0.3729 - accuracy: 0.8869#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517568/55000 [========>.....................] - ETA: 4s - loss: 0.3669 - accuracy: 0.8888#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518336/55000 [=========>....................] - ETA: 4s - loss: 0.3607 - accuracy: 0.8909#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519104/55000 [=========>....................] - ETA: 4s - loss: 0.3558 - accuracy: 0.8927#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519872/55000 [=========>....................] - ETA: 4s - loss: 0.3500 - accuracy: 0.8943#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520640/55000 [==========>...................] - ETA: 4s - loss: 0.3451 - accuracy: 0.8956#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521408/55000 [==========>...................] - ETA: 3s - loss: 0.3405 - accuracy: 0.8970#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522176/55000 [===========>..................] - ETA: 3s - loss: 0.3368 - accuracy: 0.8980#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522944/55000 [===========>..................] - ETA: 3s - loss: 0.3327 - accuracy: 0.8991#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523712/55000 [===========>..................] - ETA: 3s - loss: 0.3275 - accuracy: 0.9006#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524416/55000 [============>.................] - ETA: 3s - loss: 0.3233 - accuracy: 0.9021#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525184/55000 [============>.................] - ETA: 3s - loss: 0.3216 - accuracy: 0.9027#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525952/55000 [=============>................] - ETA: 3s - loss: 0.3181 - accuracy: 0.9037#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01526688/55000 [=============>................] - ETA: 3s - loss: 0.3155 - accuracy: 0.9045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527456/55000 [=============>................] - ETA: 2s - loss: 0.3121 - accuracy: 0.9056#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528224/55000 [==============>...............] - ETA: 2s - loss: 0.3084 - accuracy: 0.9067#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528992/55000 [==============>...............] - ETA: 2s - loss: 0.3050 - accuracy: 0.9077#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529760/55000 [===============>..............] - ETA: 2s - loss: 0.3016 - accuracy: 0.9089#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530528/55000 [===============>..............] - ETA: 2s - loss: 0.2980 - accuracy: 0.9100#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01531296/55000 [================>.............] - ETA: 2s - loss: 0.2950 - accuracy: 0.9109#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532064/55000 [================>.............] - ETA: 2s - loss: 0.2921 - accuracy: 0.9119#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532832/55000 [================>.............] - ETA: 2s - loss: 0.2904 - accuracy: 0.9124#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533600/55000 [=================>............] - ETA: 2s - loss: 0.2875 - accuracy: 0.9134#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01534368/55000 [=================>............] - ETA: 2s - loss: 0.2849 - accuracy: 0.9140#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535136/55000 [==================>...........] - ETA: 1s - loss: 0.2832 - accuracy: 0.9145#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535904/55000 [==================>...........] - ETA: 1s - loss: 0.2809 - accuracy: 0.9152#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536672/55000 [===================>..........] - ETA: 1s - loss: 0.2785 - accuracy: 0.9159#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01537440/55000 [===================>..........] - ETA: 1s - loss: 0.2755 - accuracy: 0.9168#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538208/55000 [===================>..........] - ETA: 1s - loss: 0.2726 - accuracy: 0.9176#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538944/55000 [====================>.........] - ETA: 1s - loss: 0.2704 - accuracy: 0.9182#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539680/55000 [====================>.........] - ETA: 1s - loss: 0.2677 - accuracy: 0.9191#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540448/55000 [=====================>........] - ETA: 1s - loss: 0.2660 - accuracy: 0.9198#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541216/55000 [=====================>........] - ETA: 1s - loss: 0.2638 - accuracy: 0.9203#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541952/55000 [=====================>........] - ETA: 1s - loss: 0.2612 - accuracy: 0.9211#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01542720/55000 [======================>.......] - ETA: 1s - loss: 0.2591 - accuracy: 0.9217#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543488/55000 [======================>.......] - ETA: 1s - loss: 0.2573 - accuracy: 0.9223#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544256/55000 [=======================>......] - ETA: 0s - loss: 0.2556 - accuracy: 0.9227#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545024/55000 [=======================>......] - ETA: 0s - loss: 0.2541 - accuracy: 0.9232#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545792/55000 [=======================>......] - ETA: 0s - loss: 0.2533 - accuracy: 0.9235#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01546560/55000 [========================>.....] - ETA: 0s - loss: 0.2519 - accuracy: 0.9239#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01547328/55000 [========================>.....] - ETA: 0s - loss: 0.2492 - accuracy: 0.9248#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548096/55000 [=========================>....] - ETA: 0s - loss: 0.2482 - accuracy: 0.9251#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548864/55000 [=========================>....] - ETA: 0s - loss: 0.2472 - accuracy: 0.9255#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549632/55000 [==========================>...] - ETA: 0s - loss: 0.2455 - accuracy: 0.9261#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550368/55000 [==========================>...] - ETA: 0s - loss: 0.2441 - accuracy: 0.9264#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551136/55000 [==========================>...] - ETA: 0s - loss: 0.2425 - accuracy: 0.9269#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551904/55000 [===========================>..] - ETA: 0s - loss: 0.2416 - accuracy: 0.9273#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01552672/55000 [===========================>..] - ETA: 0s - loss: 0.2405 - accuracy: 0.9276#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553408/55000 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9281#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554112/55000 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9286#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554880/55000 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9290#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01555000/55000 [==============================] - 5s 86us/sample - loss: 0.2358 - accuracy: 0.9290\u001b[0m\n",
      "\u001b[34m#015   32/10000 [..............................] - ETA: 22s - loss: 0.0160 - accuracy: 1.0000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1056/10000 [==>...........................] - ETA: 1s - loss: 0.1133 - accuracy: 0.9650 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2048/10000 [=====>........................] - ETA: 0s - loss: 0.1440 - accuracy: 0.9556#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3072/10000 [========>.....................] - ETA: 0s - loss: 0.1426 - accuracy: 0.9567#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4096/10000 [===========>..................] - ETA: 0s - loss: 0.1473 - accuracy: 0.9556#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5088/10000 [==============>...............] - ETA: 0s - loss: 0.1475 - accuracy: 0.9560#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6016/10000 [=================>............] - ETA: 0s - loss: 0.1364 - accuracy: 0.9591#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6880/10000 [===================>..........] - ETA: 0s - loss: 0.1304 - accuracy: 0.9603#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7776/10000 [======================>.......] - ETA: 0s - loss: 0.1183 - accuracy: 0.9641#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8736/10000 [=========================>....] - ETA: 0s - loss: 0.1118 - accuracy: 0.9657#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9728/10000 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9676#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510000/10000 [==============================] - 1s 60us/sample - loss: 0.1088 - accuracy: 0.9667\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:23.657490: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34m2021-08-11 12:10:24,442 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-08-11 12:10:37 Uploading - Uploading generated training model\n",
      "2021-08-11 12:10:37 Completed - Training job completed\n",
      "Training seconds: 250\n",
      "Billable seconds: 250\n"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "mnist_estimator2.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to an endpoint\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time. We will use the TensorFlow Serving container for the endpoint, because we trained with script mode. This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol. The [Using your own inference code](https://render.githubusercontent.com/view/ipynb?color_mode=auto&commit=a5c9a21e6ed70fd51ab5178f3a35461473f7b379&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6177732f616d617a6f6e2d736167656d616b65722d6578616d706c65732f613563396132316536656437306664353161623531373866336133353436313437336637623337392f736167656d616b65722d707974686f6e2d73646b2f74656e736f72666c6f775f7363726970745f6d6f64655f747261696e696e675f616e645f73657276696e672f74656e736f72666c6f775f7363726970745f6d6f64655f747261696e696e675f616e645f73657276696e672e6970796e62&nwo=aws%2Famazon-sagemaker-examples&path=sagemaker-python-sdk%2Ftensorflow_script_mode_training_and_serving%2Ftensorflow_script_mode_training_and_serving.ipynb&repository_id=107937815&repository_type=Repository) document explains how SageMaker runs inference containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 08\n",
    "predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployed the trained TensorFlow 2.1 model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 09\n",
    "predictor2 = mnist_estimator2.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the endpoint\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "import numpy as np\n",
    "\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_data.npy train_data.npy\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_labels.npy train_labels.npy\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formats of the input and the output data correspond directly to the request and response formats of the Predict method in the [TensorFlow Serving REST API](https://www.tensorflow.org/serving/api_rest). SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n",
    "\n",
    "In this example we are using a numpy array as input, which will be serialized into the simplified JSON format. In addtion, TensorFlow serving can also process multiple items at once as you can see in the following code. You can find the complete documentation on how to make predictions against a TensorFlow serving SageMaker endpoint [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst#making-predictions-against-a-sagemaker-endpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]['classes']\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "predictions2 = predictor2.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = np.argmax(predictions2['predictions'][i])\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs and then [verify](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 14\n",
    "predictor2.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
